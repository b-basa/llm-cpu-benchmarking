# llm-cpu-benchmarking

Benchmarking LLM on CPU, interested in performance.  
llama.cpp from -> https://github.com/ggml-org/llama.cpp/releases
Models should be in .gguf format and under "models".
