# llm-cpu-benchmarking
Benchmarking LLM on CPU, interested in tkn/s and memory usage.  
Get llama.cpp from -> https://github.com/ggml-org/llama.cpp/releases
